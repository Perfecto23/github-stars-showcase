import Anthropic from "@anthropic-ai/sdk";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { CohereClient } from "cohere-ai";
import OpenAI from "openai";

/**
 * AI Provider æŠ½è±¡å±‚
 * æ”¯æŒå¤šä¸ªä¸»æµ AI æ¨¡å‹å‚å•†å’Œå†…ç½® Provider
 */

// Provider æ¥å£
export interface AIProvider {
	name: string;
	model: string;
	analyze(prompt: string): Promise<string>;
}

// æ¨¡å‹ä¿¡æ¯
interface ModelInfo {
	id: string;
	name: string;
	cost: { input: number; output: number };
}

// å†…ç½® Provider é…ç½®ç±»å‹
interface BuiltinProviderConfig {
	name: string;
	baseUrl: string;
	apiKeyEnv: string;
	api: "anthropic-messages" | "openai-responses" | "google-generative-ai";
	models: ModelInfo[];
	defaultModel: string;
}

// å†…ç½® Provider é…ç½®ï¼ˆå¯ä»¥æ·»åŠ è‡ªå®šä¹‰çš„ä»£ç†æœåŠ¡ï¼‰
// æ³¨æ„ï¼šæ·»åŠ è‡ªå·±çš„ä»£ç†æ—¶ï¼Œè¯·ç¡®ä¿ API Key é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œä¸è¦ç¡¬ç¼–ç 
const BUILTIN_PROVIDERS: Record<string, BuiltinProviderConfig> = {
	// ç¤ºä¾‹ï¼šå¦‚æœä½ æœ‰è‡ªå·±çš„ API ä»£ç†ï¼Œå¯ä»¥è¿™æ ·é…ç½®ï¼š
	// "my-proxy": {
	//   name: "My Proxy",
	//   baseUrl: "https://my-proxy.example.com",
	//   apiKeyEnv: "MY_PROXY_API_KEY",
	//   api: "openai-responses",
	//   models: [{ id: "gpt-4", name: "GPT-4", cost: { input: 10, output: 30 } }],
	//   defaultModel: "gpt-4",
	// },
};

// ç¯å¢ƒå˜é‡ Provider é…ç½®ç±»å‹
interface EnvProviderConfig {
	name: string;
	models: string[];
	defaultModel: string;
	baseURL?: string;
}

// ç¯å¢ƒå˜é‡ Provider é…ç½®
const ENV_PROVIDERS: Record<string, EnvProviderConfig> = {
	anthropic: {
		name: "Anthropic",
		models: [
			"claude-sonnet-4-20250514",
			"claude-opus-4-20250514",
			"claude-3-5-sonnet-20241022",
		],
		defaultModel: "claude-sonnet-4-20250514",
	},
	openai: {
		name: "OpenAI",
		models: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
		defaultModel: "gpt-4o-mini",
	},
	google: {
		name: "Google",
		models: ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"],
		defaultModel: "gemini-2.0-flash-exp",
	},
	cohere: {
		name: "Cohere",
		models: ["command-r-plus", "command-r", "command"],
		defaultModel: "command-r",
	},
	deepseek: {
		name: "DeepSeek",
		models: ["deepseek-chat", "deepseek-reasoner"],
		defaultModel: "deepseek-chat",
		baseURL: "https://api.deepseek.com",
	},
	custom: {
		name: "Custom",
		models: [],
		defaultModel: "",
	},
};

/**
 * åˆ›å»ºå†…ç½® Provider å®ä¾‹
 */
export function createBuiltinProvider(
	providerKey: string,
	modelId?: string,
): AIProvider {
	const config = BUILTIN_PROVIDERS[providerKey];
	if (!config) {
		throw new Error(`ä¸æ”¯æŒçš„å†…ç½® provider: ${providerKey}`);
	}

	const apiKey = process.env[config.apiKeyEnv];
	if (!apiKey) {
		throw new Error(`ç¼ºå°‘ç¯å¢ƒå˜é‡: ${config.apiKeyEnv}`);
	}

	const selectedModel = modelId || config.defaultModel;
	const modelInfo = config.models.find((m) => m.id === selectedModel);
	if (!modelInfo) {
		throw new Error(`Provider ${providerKey} ä¸æ”¯æŒæ¨¡å‹: ${selectedModel}`);
	}

	switch (config.api) {
		case "anthropic-messages":
			return new AnthropicProxyProvider(apiKey, selectedModel, config.baseUrl);
		case "openai-responses":
			return new OpenAIProxyProvider(apiKey, selectedModel, config.baseUrl);
		case "google-generative-ai":
			return new GoogleProxyProvider(apiKey, selectedModel, config.baseUrl);
		default:
			throw new Error(`æœªå®ç°çš„ API ç±»å‹: ${config.api}`);
	}
}

interface CreateProviderConfig {
	provider?: string;
	apiKey?: string;
	model?: string;
	baseURL?: string;
}

/**
 * åˆ›å»º AI Provider å®ä¾‹
 */
export function createProvider(config: CreateProviderConfig): AIProvider {
	const { provider = "anthropic", apiKey, model, baseURL } = config;

	// æ£€æŸ¥æ˜¯å¦æ˜¯å†…ç½® Provider
	if (BUILTIN_PROVIDERS[provider]) {
		return createBuiltinProvider(provider, model);
	}

	const providerConfig = ENV_PROVIDERS[provider];
	if (!providerConfig) {
		throw new Error(`ä¸æ”¯æŒçš„ provider: ${provider}`);
	}

	if (!apiKey) {
		throw new Error(`Provider ${provider} éœ€è¦æä¾› API Key`);
	}

	const selectedModel = model || providerConfig.defaultModel;

	switch (provider) {
		case "anthropic":
			return new AnthropicProvider(apiKey, selectedModel);
		case "openai":
			return new OpenAIProvider(apiKey, selectedModel);
		case "google":
			return new GoogleProvider(apiKey, selectedModel);
		case "cohere":
			return new CohereProvider(apiKey, selectedModel);
		case "deepseek":
			return new DeepSeekProvider(
				apiKey,
				selectedModel,
				baseURL || providerConfig.baseURL || "",
			);
		case "custom":
			if (!baseURL) {
				throw new Error("è‡ªå®šä¹‰ provider éœ€è¦æä¾› baseURL");
			}
			return new CustomProvider(apiKey, selectedModel, baseURL);
		default:
			throw new Error(`æœªå®ç°çš„ provider: ${provider}`);
	}
}

/**
 * Anthropic Provider
 */
class AnthropicProvider implements AIProvider {
	private client: Anthropic;
	name: string;
	model: string;

	constructor(apiKey: string, model: string) {
		this.client = new Anthropic({ apiKey });
		this.model = model;
		this.name = "Anthropic";
	}

	async analyze(prompt: string): Promise<string> {
		const message = await this.client.messages.create({
			model: this.model,
			max_tokens: 4000,
			messages: [{ role: "user", content: prompt }],
		});

		const content = message.content[0];
		if (content.type !== "text") {
			throw new Error("Unexpected response type");
		}
		return content.text;
	}
}

/**
 * OpenAI Provider
 */
class OpenAIProvider implements AIProvider {
	private client: OpenAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string) {
		this.client = new OpenAI({ apiKey });
		this.model = model;
		this.name = "OpenAI";
	}

	async analyze(prompt: string): Promise<string> {
		const completion = await this.client.chat.completions.create({
			model: this.model,
			messages: [{ role: "user", content: prompt }],
			max_tokens: 4000,
		});

		return completion.choices[0].message.content || "";
	}
}

/**
 * Google Provider
 */
class GoogleProvider implements AIProvider {
	private client: GoogleGenerativeAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string) {
		this.client = new GoogleGenerativeAI(apiKey);
		this.model = model;
		this.name = "Google";
	}

	async analyze(prompt: string): Promise<string> {
		const model = this.client.getGenerativeModel({ model: this.model });
		const result = await model.generateContent(prompt);
		return result.response.text();
	}
}

/**
 * Cohere Provider
 */
class CohereProvider implements AIProvider {
	private client: CohereClient;
	name: string;
	model: string;

	constructor(apiKey: string, model: string) {
		this.client = new CohereClient({ token: apiKey });
		this.model = model;
		this.name = "Cohere";
	}

	async analyze(prompt: string): Promise<string> {
		const response = await this.client.chat({
			model: this.model,
			message: prompt,
		});

		return response.text;
	}
}

/**
 * DeepSeek Provider (å…¼å®¹ OpenAI API)
 */
class DeepSeekProvider implements AIProvider {
	private client: OpenAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string, baseURL: string) {
		this.client = new OpenAI({ apiKey, baseURL });
		this.model = model;
		this.name = "DeepSeek";
	}

	async analyze(prompt: string): Promise<string> {
		const completion = await this.client.chat.completions.create({
			model: this.model,
			messages: [{ role: "user", content: prompt }],
			max_tokens: 4000,
		});

		return completion.choices[0].message.content || "";
	}
}

/**
 * Custom Provider (å…¼å®¹ OpenAI API æ ¼å¼)
 */
class CustomProvider implements AIProvider {
	private client: OpenAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string, baseURL: string) {
		this.client = new OpenAI({ apiKey, baseURL });
		this.model = model;
		this.name = "Custom";
	}

	async analyze(prompt: string): Promise<string> {
		const completion = await this.client.chat.completions.create({
			model: this.model,
			messages: [{ role: "user", content: prompt }],
			max_tokens: 4000,
		});

		return completion.choices[0].message.content || "";
	}
}

/**
 * Anthropic Proxy Provider (æ”¯æŒè‡ªå®šä¹‰ baseURL)
 */
class AnthropicProxyProvider implements AIProvider {
	private client: Anthropic;
	name: string;
	model: string;

	constructor(apiKey: string, model: string, baseURL: string) {
		this.client = new Anthropic({ apiKey, baseURL });
		this.model = model;
		this.name = "Anthropic Proxy";
	}

	async analyze(prompt: string): Promise<string> {
		const message = await this.client.messages.create({
			model: this.model,
			max_tokens: 4000,
			messages: [{ role: "user", content: prompt }],
		});

		const content = message.content[0];
		if (content.type !== "text") {
			throw new Error("Unexpected response type");
		}
		return content.text;
	}
}

/**
 * OpenAI Proxy Provider (å…¼å®¹ OpenAI API æ ¼å¼çš„ä»£ç†)
 */
class OpenAIProxyProvider implements AIProvider {
	private client: OpenAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string, baseURL: string) {
		this.client = new OpenAI({ apiKey, baseURL });
		this.model = model;
		this.name = "OpenAI Proxy";
	}

	async analyze(prompt: string): Promise<string> {
		const completion = await this.client.chat.completions.create({
			model: this.model,
			messages: [{ role: "user", content: prompt }],
			max_tokens: 4000,
		});

		return completion.choices[0].message.content || "";
	}
}

/**
 * Google Proxy Provider (æ”¯æŒè‡ªå®šä¹‰ baseURL çš„ Google AI)
 */
class GoogleProxyProvider implements AIProvider {
	private client: OpenAI;
	name: string;
	model: string;

	constructor(apiKey: string, model: string, baseURL: string) {
		// Google AI ä»£ç†ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
		this.client = new OpenAI({ apiKey, baseURL });
		this.model = model;
		this.name = "Google Proxy";
	}

	async analyze(prompt: string): Promise<string> {
		const completion = await this.client.chat.completions.create({
			model: this.model,
			messages: [{ role: "user", content: prompt }],
			max_tokens: 4000,
		});

		return completion.choices[0].message.content || "";
	}
}

/**
 * åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒå˜é‡ providers
 */
export function listProviders() {
	return Object.entries(ENV_PROVIDERS).map(([key, config]) => ({
		key,
		name: config.name,
		models: config.models,
		defaultModel: config.defaultModel,
	}));
}

/**
 * åˆ—å‡ºæ‰€æœ‰å†…ç½® providers
 */
export function listBuiltinProviders() {
	return Object.entries(BUILTIN_PROVIDERS).map(([key, config]) => ({
		key,
		name: config.name,
		api: config.api,
		models: config.models,
		defaultModel: config.defaultModel,
	}));
}

/**
 * è·å– provider é…ç½®
 */
export function getProviderConfig(provider: string) {
	return ENV_PROVIDERS[provider];
}

/**
 * è·å–å†…ç½® provider é…ç½®
 */
export function getBuiltinProviderConfig(provider: string) {
	return BUILTIN_PROVIDERS[provider];
}

/**
 * äº¤äº’å¼é€‰æ‹© Provider å’Œ Model
 */
export async function selectProviderInteractive(): Promise<{
	providerKey: string;
	modelId: string;
	provider: AIProvider;
}> {
	const readline = await import("node:readline");
	const rl = readline.createInterface({
		input: process.stdin,
		output: process.stdout,
	});

	const question = (q: string): Promise<string> =>
		new Promise((resolve) => rl.question(q, resolve));

	console.log("\nğŸ“¦ å¯ç”¨çš„å†…ç½® Provider:\n");
	const providers = Object.entries(BUILTIN_PROVIDERS);
	providers.forEach(([key, config], index) => {
		console.log(`  ${index + 1}. ${config.name} (${key})`);
	});

	const providerIndex =
		parseInt(await question("\nè¯·é€‰æ‹© Provider (è¾“å…¥æ•°å­—): "), 10) - 1;
	if (providerIndex < 0 || providerIndex >= providers.length) {
		rl.close();
		throw new Error("æ— æ•ˆçš„é€‰æ‹©");
	}

	const [providerKey, providerConfig] = providers[providerIndex];

	console.log(`\nğŸ¤– ${providerConfig.name} å¯ç”¨çš„æ¨¡å‹:\n`);
	providerConfig.models.forEach((model, index) => {
		console.log(
			`  ${index + 1}. ${model.name} (${model.id}) - $${model.cost.input}/$${model.cost.output} per 1M tokens`,
		);
	});

	const modelIndex = parseInt(await question("\nè¯·é€‰æ‹©æ¨¡å‹ (è¾“å…¥æ•°å­—): "), 10) - 1;
	if (modelIndex < 0 || modelIndex >= providerConfig.models.length) {
		rl.close();
		throw new Error("æ— æ•ˆçš„é€‰æ‹©");
	}

	const selectedModel = providerConfig.models[modelIndex];
	rl.close();

	console.log(`\nâœ… å·²é€‰æ‹©: ${providerConfig.name} - ${selectedModel.name}\n`);

	return {
		providerKey,
		modelId: selectedModel.id,
		provider: createBuiltinProvider(providerKey, selectedModel.id),
	};
}
